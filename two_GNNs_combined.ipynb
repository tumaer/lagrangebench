{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install lagrangebench --extra-index-url=https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 03:17:40.642130: W external/xla/xla/service/gpu/nvptx_compiler.cc:703] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.52). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#export CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "import lagrangebench\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from lagrangebench.data import H5Dataset\n",
    "from lagrangebench.data.utils import numpy_collate\n",
    "from lagrangebench.evaluate import averaged_metrics\n",
    "from lagrangebench.defaults import defaults\n",
    "from typing import Callable, Iterable, List, Optional, Tuple\n",
    "from lagrangebench.evaluate.metrics import MetricsComputer, MetricsDict\n",
    "from lagrangebench.utils import (\n",
    "    broadcast_from_batch,\n",
    "    get_kinematic_mask,\n",
    "    load_haiku,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the test data\n",
    "rpf2d_test = lagrangebench.RPF2D(\"test\", n_rollout_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'case': 'RPF', 'solver': 'SPH', 'density_evolution': False, 'dim': 2, 'dx': 0.025, 'dt': 0.0005, 't_end': 2050.0, 'viscosity': 0.1, 'p_bg_factor': 0.05, 'g_ext_magnitude': 0.0, 'artificial_alpha': 0.0, 'free_slip': False, 'write_every': 100, 'is_bc_trick': False, 'sequence_length_train': 20001, 'num_trajs_train': 1, 'sequence_length_test': 10001, 'num_trajs_test': 1, 'num_particles_max': 3200, 'periodic_boundary_conditions': [True, True, True], 'bounds': [[0.0, 1.0], [0.0, 2.0]], 'default_connectivity_radius': 0.036, 'vel_mean': [0.00031023111660033464, 3.324821700508712e-13], 'vel_std': [0.03587739169597626, 0.0006851413054391742], 'acc_mean': [7.866497497843739e-08, -5.5888385824647e-15], 'acc_std': [0.00035788462264463305, 0.000308330578263849]}\n"
     ]
    }
   ],
   "source": [
    "print(rpf2d_test.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_refiner(x):\n",
    "    return lagrangebench.PDE_Refiner(\n",
    "        problem_dimension=rpf2d_test.metadata[\"dim\"],\n",
    "        latent_size=128,\n",
    "        number_of_layers=2,\n",
    "        num_mp_steps=10,\n",
    "        num_particle_types=9,  # 9 types (lagrangebench/utils.py)\n",
    "        particle_type_embedding_size=16,  # 16 set to default\n",
    "    )(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hk.without_apply_rng(hk.transform_with_state(pde_refiner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CASE SETUP\n",
    "bounds = np.array(rpf2d_test.metadata[\"bounds\"])\n",
    "box = bounds[:, 1] - bounds[:, 0]\n",
    "\n",
    "rpf_2d_case = lagrangebench.case_builder(\n",
    "    box=box,  # (x,y) array with the world size along each axis. (1.0, 1.0) for 2D TGV\n",
    "    metadata=rpf2d_test.metadata,  # metadata dictionary\n",
    "    input_seq_length=6,  # number of consecutive time steps fed to the model\n",
    "    isotropic_norm=False,  # whether to normalize each dimension independently\n",
    "    noise_std=0.0,  # noise standard deviation used by the random-walk noise\n",
    "    external_force_fn = rpf2d_test.external_force_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL: need to write a rollout loop combining both models: \n",
    "#path for only the denoising model: ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-194222\n",
    "#path for k = 0 model : ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-192702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_models_infer(\n",
    "    model: hk.TransformedWithState,\n",
    "    case,\n",
    "    data_test: H5Dataset,\n",
    "    metrics: List = [\"mse\"],\n",
    "    rollout_dir: Optional[str] = None,\n",
    "    eval_n_trajs: int = defaults.eval_n_trajs,\n",
    "    n_rollout_steps: int = defaults.n_rollout_steps,\n",
    "    out_type: str = defaults.out_type,\n",
    "    n_extrap_steps:  int = defaults.n_extrap_steps,\n",
    "    seed: int = defaults.seed,\n",
    "    metrics_stride: int = defaults.metrics_stride,\n",
    "    **kwargs,):\n",
    "    \n",
    "    key, seed_worker, generator = set_seed(seed)\n",
    "    \n",
    "    loader_test = DataLoader(\n",
    "        dataset=data_test,\n",
    "        batch_size=1,\n",
    "        collate_fn=numpy_collate,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        )\n",
    "    \n",
    "    metrics_computer = MetricsComputer(\n",
    "        metrics,\n",
    "        dist_fn=case.displacement,\n",
    "        metadata=data_test.metadata,\n",
    "        input_seq_length=data_test.input_seq_length,\n",
    "        stride=metrics_stride,\n",
    "    )\n",
    "    \n",
    "    model_apply = jax.jit(model.apply)\n",
    "    \n",
    "    # init values\n",
    "    pos_input_and_target, particle_type = next(iter(loader_test))\n",
    "    sample = (pos_input_and_target[0], particle_type[0])\n",
    "    \n",
    "    denoising_model_dir = os.path.join(\"ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-194222\", \"best\")\n",
    "    no_denoising_model_dir = os.path.join(\"ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-192702\", \"best\")\n",
    "    \n",
    "    #denoising_model_dir = \"ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-194222\"\n",
    "    #no_denoising_model_dir = \"ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-192702\"\n",
    "\n",
    "    #Load the models\n",
    "    params_denoising, state_denoising, _, _ = load_haiku(denoising_model_dir)\n",
    "    params_base, state_base, _, _ = load_haiku(no_denoising_model_dir) \n",
    "\n",
    "    \n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    num_refinement_steps = kwargs[\"num_refinement_steps\"]\n",
    "    sigma_min = kwargs[\"sigma_min\"]\n",
    "    k  = jax.random.randint(subkey, (), 0, num_refinement_steps+1)\n",
    "    is_k_zero = jnp.where(k==0, True, False)\n",
    "    key, _, _, neighbors = case.allocate_pde_refiner(key, sample, k,is_k_zero,sigma_min,num_refinement_steps)\n",
    "    \n",
    "    #eval_rollout_pde_refiner() begins\n",
    "    t_window = loader_test.dataset.input_seq_length #2\n",
    "    eval_metrics = {}\n",
    "\n",
    "    for i, traj_i in enumerate(loader_test): #for every trajectory in the test set\n",
    "        # remove batch dimension\n",
    "        assert traj_i[0].shape[0] == 1, \"Batch dimension should be 1\"\n",
    "        traj_i = broadcast_from_batch(traj_i, index=0)  \n",
    "\n",
    "        #eval_single_rollout_pde_refiner() begins\n",
    "        \n",
    "        pos_input, particle_type = traj_i #pos_input has the shape (3200,26,2) it loaded 20+6 positions for 3200 particles, 20 being the number of rollout steps and 6 is the input sequence length\n",
    "\n",
    "        initial_positions = pos_input[:, 0:t_window]  # (n_nodes, t_window, dim), t_window = 2 \n",
    "        traj_len = n_rollout_steps + 0  # (n_nodes, traj_len - t_window, dim)\n",
    "        ground_truth_positions = pos_input[:, t_window : t_window + traj_len] #shape (3200,20,2)\n",
    "        current_positions = initial_positions  \n",
    "        n_nodes, _, dim = ground_truth_positions.shape \n",
    "\n",
    "        predictions = jnp.zeros((traj_len, n_nodes, dim)) \n",
    "        \n",
    "        step = 0\n",
    "        while step < n_rollout_steps + n_extrap_steps :  #runs 20 times\n",
    "            sample = (current_positions, particle_type)\n",
    "            features, neighbors = case.preprocess_eval_pde_refiner(sample, neighbors) #neighbour list is updated \n",
    "            \n",
    "            if neighbors.did_buffer_overflow is True:\n",
    "                edges_ = neighbors.idx.shape\n",
    "                print(f\"(eval) Reallocate neighbors list {edges_} at step {step}\")\n",
    "                _, neighbors = case.allocate_eval_pde_refiner(sample)  #if there is any overflow,then neighbour list is allocated\n",
    "                print(f\"(eval) To list {neighbors.idx.shape}\")\n",
    "\n",
    "                continue\n",
    "            \n",
    "            features['u_t_noised'] = jnp.zeros((features['vel_hist'].shape[0],2)) #0's\n",
    "            features['k']= jnp.tile(0, (features['vel_hist'].shape[0],)) #set to 0\n",
    "            \n",
    "            #use the k=0 model for predicting the first value\n",
    "            u_hat_t , _ = model_apply(params_base, state_base, (features, particle_type)) #predicts the 'acc' for gns and 'noise' for pde refiner\n",
    "\n",
    "            max_refinement_steps=kwargs[\"num_refinement_steps\"]\n",
    "            min_noise_std = kwargs['sigma_min'] \n",
    "            #key = kwargs[\"key\"]\n",
    "            \n",
    "            for k in range(1, max_refinement_steps+1): #Refinement loop\n",
    "                \n",
    "                key, subkey = jax.random.split(key, 2)\n",
    "\n",
    "                noise_std =  min_noise_std**(k/max_refinement_steps)\n",
    "\n",
    "                noise = jax.random.normal(subkey, jnp.zeros((features['vel_hist'].shape[0],2)).shape)\n",
    "\n",
    "                features['u_t_noised'] = u_hat_t['noise'] + noise_std*noise\n",
    "\n",
    "                #Modify the k value before sending it to the model\n",
    "                features[\"k\"] = jnp.tile(k, (features[\"vel_hist\"].shape[0],))\n",
    "                features[\"k\"] = features[\"k\"] * (1000 / max_refinement_steps)\n",
    "                \n",
    "                #use the denoising model for predicting the subsequent values\n",
    "                pred, _ = model_apply(params_denoising, state_denoising, (features, particle_type))\n",
    "                #pred is a dictionary with key 'noise' \n",
    "                u_hat_t['noise'] = features['u_t_noised'] - pred['noise']*noise_std\n",
    "\n",
    "            refined_acc = {\"acc\": u_hat_t['noise']}\n",
    "\n",
    "            next_position = case.integrate(refined_acc, current_positions)\n",
    "\n",
    "            #Assuming n_extrap_steps = 0\n",
    "            kinematic_mask = get_kinematic_mask(particle_type)\n",
    "            next_position_ground_truth = ground_truth_positions[:, step]\n",
    "\n",
    "            next_position = jnp.where(kinematic_mask[:, None], next_position_ground_truth, next_position)\n",
    "            \n",
    "            predictions = predictions.at[step].set(next_position) #shape of predictions: (20,3200,2)\n",
    "            current_positions = jnp.concatenate([current_positions[:, 1:], next_position[:, None, :]], axis=1) #shape of current_positions: (3200,6,2)\n",
    "            step += 1\n",
    "\n",
    "        ground_truth_positions = ground_truth_positions.transpose(1, 0, 2)\n",
    "        \n",
    "        metrics = metrics_computer(predictions, ground_truth_positions)\n",
    "        \n",
    "        eval_metrics[f\"rollout_{i}\"] = metrics\n",
    "        \n",
    "        if (i + 1) == eval_n_trajs:\n",
    "            break\n",
    "    \n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-194222/best at step 400000\n",
      "Loaded model from ckp/rpf_2d_pde_ref_algo_1/pde_refiner_rpf2d_20240218-192702/best at step 90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hramachandran/lagrangebench/lagrangebench/case_setup/case.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  pos_input = jnp.asarray(\n",
      "/home/hramachandran/lagrangebench/lagrangebench/case_setup/case.py:283: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  pos_input = jnp.asarray(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Metrics on Test split\n",
      "{'val/loss': 9.800620100956317e-06, 'val/mse1': 3.2204882585938157e-09, 'val/mse5': 1.856349749843981e-07, 'val/mse10': 1.2178943878578725e-06, 'val/stdloss': 1.8164792262099053e-06, 'val/stdmse1': 5.463558476193826e-10, 'val/stdmse5': 3.424190235076483e-08, 'val/stdmse10': 2.4968374148512453e-07}\n"
     ]
    }
   ],
   "source": [
    "metrics = two_models_infer(  \n",
    "    model,\n",
    "    rpf_2d_case,\n",
    "    rpf2d_test, \n",
    "    metrics=[\"mse\"],  #mse, sink_horn and e_kin\n",
    "    rollout_dir=\"rollouts/\",\n",
    "    eval_n_trajs=-1, #Default is -1\n",
    "    n_rollout_steps=20, \n",
    "    out_type=\"pkl\", \n",
    "    n_extrap_steps=0,\n",
    "    seed=0,\n",
    "    metrics_stride=1, \n",
    "    num_refinement_steps = 3,\n",
    "    sigma_min = 1e-7,\n",
    ")\n",
    "\n",
    "print(f\"Averaged Metrics on Test split\")\n",
    "print(averaged_metrics(metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
